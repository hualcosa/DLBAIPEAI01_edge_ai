{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-27 17:46:42.111043: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2023-12-27 17:46:42.111066: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2023-12-27 17:46:42.111241: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /home/hualcosa/Documents/iu_project_edge_ai/project_files/artifacts/models/age\n",
      "2023-12-27 17:46:42.114133: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2023-12-27 17:46:42.114168: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /home/hualcosa/Documents/iu_project_edge_ai/project_files/artifacts/models/age\n",
      "2023-12-27 17:46:42.123783: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2023-12-27 17:46:42.423709: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /home/hualcosa/Documents/iu_project_edge_ai/project_files/artifacts/models/age\n",
      "2023-12-27 17:46:42.446399: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 335159 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 9, Total Ops 64, % non-converted = 14.06 %\n",
      " * 9 ARITH ops\n",
      "\n",
      "- arith.constant:    9 occurrences  (f32: 7, i32: 2)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 16)\n",
      "  (f32: 5)\n",
      "  (f32: 13)\n",
      "  (uq_8: 16)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "2023-12-27 17:47:13.132823: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2023-12-27 17:47:13.132849: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2023-12-27 17:47:13.133018: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /home/hualcosa/Documents/iu_project_edge_ai/project_files/artifacts/models/emotion\n",
      "2023-12-27 17:47:13.134402: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2023-12-27 17:47:13.134413: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /home/hualcosa/Documents/iu_project_edge_ai/project_files/artifacts/models/emotion\n",
      "2023-12-27 17:47:13.137268: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2023-12-27 17:47:13.171874: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /home/hualcosa/Documents/iu_project_edge_ai/project_files/artifacts/models/emotion\n",
      "2023-12-27 17:47:13.184715: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 51698 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 17, Total Ops 33, % non-converted = 51.52 %\n",
      " * 17 ARITH ops\n",
      "\n",
      "- arith.constant:   17 occurrences  (f32: 16, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 2)\n",
      "  (f32: 5)\n",
      "  (f32: 3)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "2023-12-27 17:47:14.017780: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2023-12-27 17:47:14.017806: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2023-12-27 17:47:14.017995: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /home/hualcosa/Documents/iu_project_edge_ai/project_files/artifacts/models/gender\n",
      "2023-12-27 17:47:14.021689: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2023-12-27 17:47:14.021706: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /home/hualcosa/Documents/iu_project_edge_ai/project_files/artifacts/models/gender\n",
      "2023-12-27 17:47:14.030064: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2023-12-27 17:47:14.292738: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /home/hualcosa/Documents/iu_project_edge_ai/project_files/artifacts/models/gender\n",
      "2023-12-27 17:47:14.316702: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 298708 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 9, Total Ops 64, % non-converted = 14.06 %\n",
      " * 9 ARITH ops\n",
      "\n",
      "- arith.constant:    9 occurrences  (f32: 7, i32: 2)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 16)\n",
      "  (f32: 5)\n",
      "  (f32: 13)\n",
      "  (uq_8: 16)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "age_path = '/home/hualcosa/Documents/iu_project_edge_ai/project_files/artifacts/models/age'\n",
    "emotion_path = '/home/hualcosa/Documents/iu_project_edge_ai/project_files/artifacts/models/emotion'\n",
    "gender_path = '/home/hualcosa/Documents/iu_project_edge_ai/project_files/artifacts/models/gender'\n",
    "\n",
    "for model_name, saved_model_dir in zip([\"age\", \"emotion\", \"gender\"],[age_path, emotion_path, gender_path]):\n",
    "    # Convert the model\n",
    "    converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir) # path to the SavedModel directory\n",
    "    # age and gender models needs to go through a post-training quantization process, because the original models are too big to be imported in an adroid project.\n",
    "    # see more details about post training quantization here: https://www.tensorflow.org/lite/performance/post_training_quant#convert_to_a_tensorflow_lite_model\n",
    "    if model_name in {\"age\", \"gender\"}:\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "    tflite_model = converter.convert()\n",
    "\n",
    "    # Save the model.\n",
    "    with open(f'/home/hualcosa/Documents/iu_project_edge_ai/project_files/artifacts/models/{model_name}_model.tflite', 'wb') as f:\n",
    "        f.write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edge_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
